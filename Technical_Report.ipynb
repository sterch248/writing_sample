{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Technical Report: Classifying Sentiment From Stock Market Moves\n",
    "___________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Problem Statement\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Historically, Machine Learning Natural Language Processing (NLP), or deriving Computational meaning from human language, has been used to attempt to make accurate predictions on Publicly Traded Stocks. \n",
    "\n",
    "There are many challenges to approaching this problem. Mainly, the Stock Market generally trades with a lot of noise, or randomly within a range, before showing a true trend and general investors get overly emotional at the top and bottom of Stock moves. Since investors are usually reacting to market moves, predicting a Stock Market move from something it influences is very difficult.\n",
    "\n",
    "If this assumption is true, that investors emotions are based off of changes in the Stock Market, then using the Stock Market to predict investor sentiment is a possibility.\n",
    "\n",
    "The use case for this model is to help Broker Dealers, Investment Fund Companies, and Money Managers maintain strong relationships with their investors. One of the top reasons why clients leave their advisers is the lack of communication or setting expectations:\n",
    "\n",
    " \"Clients don't necessarily fire advisors only because of performance, but rather because the advisor never communicates with them,\" (source: https://www.investopedia.com/articles/professionals/071113/why-clients-fire-financial-advisors.asp)\n",
    "\n",
    "\n",
    "If this model can accurately predict when broad base investor sentiment turns negative, professionals can time their public relations or client outreach, at the right moments of market volatility, to maintain a proactive perception amongst their customer base. \n",
    "\n",
    "In addition, the model can also be used to predict positive sentiment to help advisors time when they solicit more business from the excitement of investors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through Pushshift API, I used a function that collected over 1.6 million comments on 4 different investing related SubReddits with over 1.5 million subscribers. This was done over a period of 2 years (2017 - 2018).\n",
    "\n",
    "Stock market data was collected through Yahoo Finance. I gathered S&P 500 (an Indice that is composed of the 500 largest publicly traded companies, in terms of market cap) data from the same 2 year time period.\n",
    "\n",
    "Please note, due to the large data size, these CSV files will not be included in this repository.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Explained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 1.6 million comment corpus was run through Vader Sentiment Analysis. This pretrained NLP library specializes in Social Media sentiment analysis. \n",
    "\n",
    "Positive and negative sentiment is derived from the use of language:\n",
    "\n",
    "- Positive Sentiment: \"This is great, I made so much money\" \n",
    "- Negative Sentiment: \"I can't believe how dumb I was\"\n",
    "\n",
    "Some challenge with traditional modeling of sentiment derived from social media:\n",
    "- \"WOW, YOU CAME UP WITH THAT...\" - this may appear to be neutral but the all caps indicates sarcasm\n",
    "- \"That is not bad way to think about it.\" -the use of not would drive traditional models to believe this comment to be negative, even though it has a slightly positive sentiment.\n",
    "\n",
    "From the Vader Sentiment Libraries (source: https://github.com/cjhutto/vaderSentiment), Vader Sentiment is specifically designed to combat older model's bias towards social media content and address:\n",
    "\n",
    "*examples of typical use cases for sentiment analysis, including proper handling of sentences with:*\n",
    "\n",
    "- *typical negations (e.g., \"not good\")*\n",
    "- *use of contractions as negations (e.g., \"wasn't very good\")*\n",
    "- *conventional use of punctuation to signal increased sentiment intensity (e.g., \"Good!!!\")*\n",
    "- *conventional use of word-shape to signal emphasis (e.g., using ALL CAPS for words/phrases)*\n",
    "- *using degree modifiers to alter sentiment intensity (e.g., intensity boosters such as \"very\" and intensity dampeners such as \"kind of\")*\n",
    "- *understanding many sentiment-laden slang words (e.g., 'sux')*\n",
    "- *understanding many sentiment-laden slang words as modifiers such as 'uber' or 'friggin' or 'kinda'*\n",
    "- *understanding many sentiment-laden emoticons such as :) and :D*\n",
    "- *translating utf-8 encoded emojis such as üíò and üíã and üòÅ*\n",
    "- *understanding sentiment-laden initialisms and acronyms (for example: 'lol')*\n",
    "- *more examples of tricky sentences that confuse other sentiment analysis tools*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Sentiment Distribution**\n",
    "\n",
    "After evaluating the sentiment, the distribution of Compound Sentiment(from a -1 to 1 scale, with -1 being negative sentiment and +1 being positive sentiment):\n",
    "\n",
    "![histogram_sentiment](./data/sentiment_histogram.png)\n",
    "\n",
    "The overall count looks close to normal distribution but the mean is the mode at 0 Sentiment (Neutral). Overall, 13% of the the posts were neutral.\n",
    "\n",
    "Keeping in mind the problem statement, the goal is to predict more polarizing sentiment (extremely positive or negative). This will pose challenges for the model to learn negative and positive sentiment when a large distribution is at 0 or neutral.\n",
    "\n",
    "When looking at the percentage change in sentiment, day over day:\n",
    "\n",
    "![sent_pct_change](./data/sentiment_pct.png)\n",
    "\n",
    "The distribution is more normal and less concentrated at 0 Sentiment. The mode is still at 0. There are slightly more positive day over day change than negative change and, in terms of absolute value, the maximum positive score is much higher than the negative positive score.\n",
    "\n",
    "| Change in Sentiment | Ratio |\n",
    "| --- | --- |\n",
    "| Positive (0) | 0.5088 |\n",
    "| Negative (1) | 0.4911 |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stock Market Analysis**\n",
    "\n",
    "During the 2017-2018 time period, The market was in a huge uptrend until the very end of 2018. The S&P 500 represents the 500 largest companies and is used as a gauge for the broad based equity markets. This will be the measure for stocks that will be used.\n",
    "\n",
    "![sp500](./data/sp500_sma.png)\n",
    "\n",
    "Generally, the S&P 500 was trading above the 50 Day Simple Moving Average(SMA). This trend is used to identify the noise, or the natural range, of the Stock Market.\n",
    "\n",
    "If we examine days that S&P 500 moved outside the Interquartile range (IQR, the 2 middle quarters of a distribution),\n",
    "\n",
    "![quartiles](./data/sp500_quartiles.png)\n",
    "\n",
    "250 days out of 735 total days fall under this criteria. We will examine these days to see if they influence Sentiment negatively or positively.\n",
    "\n",
    "And if examined at the points where they happen relative to the day over day S&P 500 stock chart:\n",
    "\n",
    "![s&pdoverd](./data/sp500_with_target.png)\n",
    "\n",
    "A good portion of the 250 days fall on the peaks and valleys of this percentage change chart.\n",
    "\n",
    "When reviewed over Sentiment Day Over Day Changes:\n",
    "\n",
    "![sentdoverd](./data/sentiments_on_stock_moves.png)\n",
    "\n",
    "Sentiment change is in a tighter range than the stock market but these points where the stock market moves outside of the IQR. The points looks more  in the noise of the changes in Sentiment Score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Target:  Change in Sentiment\n",
    "\n",
    "(from earlier)\n",
    "\n",
    "| Change in Sentiment | Ratio |\n",
    "| --- | --- |\n",
    "| Positive (0) | 0.5088 |\n",
    "| Negative (1) | 0.4911 |\n",
    "\n",
    "- The Baseline Score is 50.9%. Negative Sentiment is Class 1 because there is a higher risk for Investment Professionals when this increases. Losing clients and reputation could be highly possible if proper outreach in uncertain Market conditions.\n",
    "\n",
    "- Reddit Comments were analyzed and narrowed down from 1.6 million comments to 557,000 comments \n",
    "\n",
    "- The first model will be on the NLP of the Reddit Comment and properly classifying changing Sentiment\n",
    "\n",
    "- The second model will be on engineered features of the Stock Market to predict where movement in it can predict changes in Sentiment\n",
    "\n",
    "\n",
    "Since the Compound Sentiment was derived from the Reddit Comments, I will not be using words extracted from there to help predict with the Stock Market features to predict Sentiment. I want to avoid having elements that are a part of the target.\n",
    "\n",
    "I am using CountVectorizer and Logistic Regression models as my main tools for NLP. \n",
    "\n",
    "CountVectorizer turns frequently appearing words into tokens (variables) that is vectorized (assigned a vector, such as cat = (0, 2) or dog = (1, 3)) to be analyzed. \n",
    "\n",
    "Logistic Regression picks continuous probabilities between 0 and 1. It uses the vectorized words to predict the targets and allows interpretation of the features used.\n",
    "\n",
    "The outcomes from the predictions fall under 4 categories:\n",
    "\n",
    "\n",
    "- True Positive (tp): The Sentiment changed negatively, and the model predicted Sentiment changed negatively\n",
    "- False Positive (fp): The Sentiment changed positively, and the model predicted Sentiment changed negatively\n",
    "- True Negative (tn): The Sentiment changed positively, and the model predicted Sentiment changed positively\n",
    "- False Negative (fn): The Sentiment changed negatively, and the model predicted Sentiment changed positively\n",
    "\n",
    "\n",
    "Accuracy, Sensitivity, Specificity are the metrics that I will focus on for the validation methods.\n",
    "\n",
    "- Accuracy: Correct Predictions / All Predictions\n",
    "- Sensitivity: tp / (tp + fn)\n",
    "- Specificity: tn / (tn + fp)\n",
    "\n",
    "\n",
    "For predicting change in Sentiment with Stock Price movement, I will use logistic regression, mainly for interpretability, and eventually use a Recurrent Neural Network (RNN) due to the sequential time aspect.\n",
    "\n",
    "Please note: this model is not trying to predict future stock price movement. I will not address time series principles (i.e. stationarity) for this project because it is not in the scope of this model. The assumption is that recent Sentiment is not correlated to past Sentiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reddit (NLP) Modeling and Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using CountVectorizer, I extracted 2000 words (features) that met the metrics of the tuned hyperparameters (a value set before modeling). These features were then used as the basis for the Logistic Regression model to learn and predict the Target 1 Class (Negative change in Sentiment) or Target 0 Class (Positive change in Sentiment). \n",
    "\n",
    "The data was split into 2 sections:\n",
    "- 80% Training Set (for the model to learn on)\n",
    "- 20% Test Set (for the model to predict on)\n",
    "\n",
    "Two accuracy scores are produced: one for Training and one for Test. The Test score is the primary focus.\n",
    "\n",
    "The Logistic Regression model scored:\n",
    "Training Accuracy: 100%\n",
    "Test Accuracy: 56.0%\n",
    "Sensitivity: 44.9%\n",
    "Specificity: 66.3%\n",
    "\n",
    "| --- | --- | Actual | Class |\n",
    "| --- | --- | --- | --- |\n",
    "| --- | --- | Class 1 | Class 0 |\n",
    "| **Predicted** | Class 1 | 40 (TP) | 32 (FP) |\n",
    "| **Class** | Class 0 | 49 (FN) | 63 (TN) |\n",
    "\n",
    "The model was overfit, meaning it learned the Training data, but failed to generalize well to unseen data (Test).\n",
    "\n",
    "Sensitivity suffered due to a relatively high false negative count more than Specificity.\n",
    "\n",
    "The top 15 words that increased the probability of predicting the right target class (i.e. the appearance of the word, \"subprime\", increased the odds of a statement having negative sentiment by 1.2 times):\n",
    "![weights](./data/logregweights.png)\n",
    "\n",
    "Another metric that was used was Receiver Operator Curve (AUC ROC), which measures the overlap between the 2 target classes. The metric is generally between 0.5 and 1 (it is possible to get as low as 0 but that can be fixed). If the score is at 0.5, then your positive and negative distributions completely overlap each other, which is the worst outcome.\n",
    "\n",
    "The AUC ROC score was 0.556, which is close to the worst case scenario.\n",
    "\n",
    "One way to address overfitting, is to use Principal Component Analysis, a feature extraction method that uses the features that explain a majority of the variance that exists in your data. These will be used to model instead of all the features.\n",
    "\n",
    "![nlp_var_exp](./data/nlp_var_exp.png)\n",
    "\n",
    "Since 70% of the variance was explained by 150 words, the remaining 1850 words were not used in the second Logistic Regression Model.\n",
    "\n",
    "The main drawback to this process is that interpretability (versus Logistic Regression, as an example) is diminished. The accuracy scores for the second model were:\n",
    "\n",
    "- Training Accuracy: 74.4%\n",
    "- Test Accuracy: 58.7%\n",
    "- AUC ROC: 0.607\n",
    "- Sensitivity: 56.2%\n",
    "- Specificity: 65.3%\n",
    "\n",
    "There was a 2.7% Test Accuracy (4.8% increase) improvement over the first model. The model did perform above the baseline, 50.9%. The AUC ROC and Specificity improved at a slight decrease of Sensitivity.\n",
    "\n",
    "A RNN model was tested but scored worse than the second Logistic Regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stock Modeling and Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I mainly feature engineered different rolling averages and metrics for both S&P 500 price changes and volume. This was combined with word counts and comment counts for each corresponding day. Three models were used:\n",
    "\n",
    "- RandomForest (an ensemble, tree based method that splits on a randomly selected amount of features and splits sections where it attempts to divide the data into homogenous groups)\n",
    "- Logistic Regression (1 without PCA and 1 with PCA)\n",
    "- RNN \n",
    "\n",
    "A total of 27 Features was used for the 1st Logistic Regression Model.\n",
    "\n",
    "RandomForest severely overfit and scored:\n",
    "- Training Accuracy: 96%\n",
    "- Test Accuracy: 50%\n",
    "\n",
    "RNN overfit and scored (8th Epoch):\n",
    "without PCA\n",
    "- Training Accuracy: 69%\n",
    "- Test Accuracy: 56%\n",
    "\n",
    "Logistic Regression was still overfit, but has interpretability (and was less overfit than RandomForest):\n",
    "without PCA\n",
    "- Training Accuracy: 60.9%\n",
    "- Test Accuracy: 53.8%\n",
    "- Sensitivity: 69.6%\n",
    "- Specificity: 38.9%\n",
    "- AUC ROC: 0.543\n",
    "\n",
    "| --- | --- | Actual | Class |\n",
    "| --- | --- | --- | --- |\n",
    "| --- | --- | Class 1 | Class 0 |\n",
    "| **Predicted** | Class 1 | 62 (TP) | 58 (FP) |\n",
    "| **Class** | Class 0 | 27 (FN) | 37 (TN) |\n",
    "\n",
    "Compared to the NLP modeling, both suffered from bad AUC ROC scores. Instead of having low Sensitivity, the stock model suffered from low Specificity (high fp).\n",
    "\n",
    "with PCA\n",
    "- 11 out of the 27 Features were used\n",
    "- Training Accuracy: 58.4%\n",
    "- Test Accuracy: 57.6%\n",
    "- Sensitivity: 60.7%\n",
    "- Specificity: 54.7%\n",
    "- AUC ROC: 0.577\n",
    "\n",
    "Other than Training Score and Sensitivity, all the other metrics improved. Although the Logistic Regression model with PCA performed better than the baseline, it did worse overall compared to the NLP model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance of my models did not consistently predict changes in negative and positive Sentiment. There were initial concerns about lack of signal with my variables and targets. This concern was proven true.\n",
    "\n",
    "This is the Correlation of all numeric Features (not all were used) to Sentiment Score and Target Label (1, 0)\n",
    "\n",
    "| Feature | Compound Sentiment | Sentiment Label |\n",
    "| --- | --- | --- |\n",
    "| word_count | -0.0688 | -0.0716 |\n",
    "| post_count | -0.0995 | -0.1036 |\n",
    "| close_SMA50 | -0.0389 | -0.0211 |\n",
    "| stock_close | 0.102 | 0.1115 |\n",
    "| stock_SMA50_diff | 0.0547 | 0.0566 |\n",
    "| volume_SMA50 | -0.0121 | -0.0221 |\n",
    "| stock_volume | -0.0547 | -0.0541 |\n",
    "| volume_SMA50_diff | -0.0578 | -0.0368 |\n",
    "| 5_diff_SMA_50 | -0.0606 | -0.047 |\n",
    "| 5_diff_stock_close | 0.0508 | 0.0704 |\n",
    "| 5_diff_stock_vs_SMA50 | -0.0112 | -0.0148 |\n",
    "| 5_diff_vSMA50 | 0.0111 | -0.0048 |\n",
    "| 5_diff_volume | -0.0628 | -0.0498 |\n",
    "| 5_diff_volume_vs_SMA50 | 0.065 | 0.0816 |\n",
    "| close_1day_vs_5day | -0.0036 | -0.0204 |\n",
    "| volume_1day_vs_5day | 0.0229 | 0.0105 |\n",
    "| sp500_5days_after | -0.0774 | -0.0686 |\n",
    "| sp500_10days_after | -0.0536 | -0.0411 |\n",
    "| sp500_20days_after | -0.0973 | -0.0787 |\n",
    "| target | -0.2552 | -0.3126 |\n",
    "| target_5days | -0.0148 | -0.0426 |\n",
    "| stock_move_bins_0.0 | 0.0739 | 0.0574 |\n",
    "| stock_move_bins_1.0 | -0.0461 | -0.0429 |\n",
    "| stock_move_bins_2.0 | -0.0005 | -0.0038 |\n",
    "| stock_move_bins_3.0 | -0.052 | -0.03 |\n",
    "| volume_move_bins_0.0 | 0.0859 | 0.089 |\n",
    "| volume_move_bins_1.0 | -0.005 | -0.016 |\n",
    "| volume_move_bins_2.0 | -0.0525 | -0.066 |\n",
    "| volume_move_bins_3.0 | -0.0566 | -0.0363 |\n",
    "\n",
    "None of the independent variables have strong correlations (close to 0) to the target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Develop or Improve Sentiment Scoring - Although Vader is a popular social media sentiment analyzer, the way people communicate on the stock market is a little different from general social media. Further research and tuning will be required to improve the precision of the score to reflect sentiment.\n",
    "\n",
    "\n",
    "- Gather more NLP data - Alternate sources with less moderated discussion need to be explored. More free form text with no initial prompt needs to be collected to generate less neutral speech writing. Any sentiment analyzer will have difficulty with posts that are 50% neutral wording with a mix of other sentiments.\n",
    "\n",
    "\n",
    "- Add additional individual Stocks and Indices (i.e. Russell 2000) - Although the S&P 500 represents a broad base of stocks, popular stocks and sectors may generate more polarizing sentiment. It is worth exploring how people react to different equities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Vader Sentiment Analysis Documentation:** https://github.com/cjhutto/vaderSentiment\n",
    "- **Vader Sentiment Study:** Hutto, C.J. & Gilbert, E.E. (2014). VADER: A Parsimonious Rule-based Model for Sentiment Analysis of Social Media Text. Eighth International Conference on Weblogs and Social Media (ICWSM-14). Ann Arbor, MI, June 2014."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
